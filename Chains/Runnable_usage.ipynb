{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnable Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anirban\\AppData\\Local\\Temp\\ipykernel_17656\\3332327995.py:16: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model1 = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "import os\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "groq_token = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Set base URL for Groq (OpenAI-compatible)\n",
    "groq_base_url = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# Model 1: Mixtral-8x7B (via Groq)\n",
    "model1 = ChatOpenAI(\n",
    "    openai_api_key=groq_token,\n",
    "    openai_api_base=groq_base_url,\n",
    "    model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did India get kicked out of the bar?\n",
      "\n",
      "Because it was making too many curries about its problems! (get it? curries... like complaints, but also a type of Indian dish)\n"
     ]
    }
   ],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template='write a joke about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "parser=StrOutputParser()\n",
    "chain=RunnableSequence(prompt1,model1,parser)\n",
    "print(chain.invoke({'topic':\"India\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The joke is a play on words. 'Curries' has a double meaning here. \n",
      "\n",
      "1. 'Curries' refers to a type of popular Indian dish (like chicken curry, vegetable curry, etc.).\n",
      "2. 'Curries' sounds similar to 'carries', which can also mean 'makes' or 'has'. In this case, it's used in a phrase 'making too many curries about the bill', which sounds similar to 'making too many carries about the bill'.\n",
      "\n",
      "The punchline 'making too many curries about the bill' is a pun on 'making too many carries about the bill', which means complaining or making a fuss about the bill. \n",
      "\n",
      "The joke relies on the listener being familiar with Indian cuisine (curries) and understanding the wordplay. The humor comes from the unexpected twist on the phrase and the connection to India, which adds to the cleverness of the joke.\n"
     ]
    }
   ],
   "source": [
    "prompt2=PromptTemplate(\n",
    "    template='Explain the following joke-{text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "chain=RunnableSequence(prompt1,model1,parser,prompt2,model1,parser)\n",
    "print(chain.invoke({'topic':'India'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnable Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a potential LinkedIn post on the latest news about Agentic AI:\n",
      "\n",
      "**Post Title:** \"The Future of AI is Here: Agentic AI Takes Center Stage\"\n",
      "\n",
      "**Post Content:**\n",
      "\n",
      "Exciting developments in the world of Artificial Intelligence! Agentic AI, a rapidly emerging field, is revolutionizing the way we interact with technology.\n",
      "\n",
      "For those who may be new to the concept, Agentic AI refers to a type of AI that can act autonomously, making decisions and taking actions on its own, while also being able to adapt and learn from its environment.\n",
      "\n",
      "Here are some of the latest updates on Agentic AI:\n",
      "\n",
      " **Recent Breakthroughs:** Researchers at [leading institutions] have made significant advancements in developing Agentic AI systems that can learn from complex data sets, reason, and make decisions in real-time.\n",
      "\n",
      " **Industry Applications:** Companies like [leading companies] are already exploring the potential of Agentic AI in various industries, including healthcare, finance, and transportation.\n",
      "\n",
      " **The Future of Work:** Agentic AI has the potential to automate routine and repetitive tasks, freeing up human workers to focus on higher-value tasks that require creativity, empathy, and problem-solving skills.\n",
      "\n",
      " **Ethics and Governance:** As Agentic AI becomes more prevalent, it's essential that we prioritize ethics and governance to ensure that these systems are developed and deployed responsibly.\n",
      "\n",
      "Stay ahead of the curve and join the conversation on Agentic AI! What are your thoughts on the potential impact of Agentic AI on industries and society?\n",
      "\n",
      "**Hashtags:** #AgenticAI #ArtificialIntelligence #AutonomousSystems #FutureOfWork #Innovation #Technology\n",
      "\n",
      "**Tagged:** [Optional: Tag relevant influencers, researchers, or companies in the Agentic AI space]\n",
      "\n",
      "Feel free to customize the post to fit your style and interests!\n",
      "Here's a Twitter post about the latest news on Agentic AI:\n",
      "\n",
      "\"Breaking: Agentic AI takes center stage! Latest advancements in agentic AI systems are revolutionizing industries. From autonomous decision-making to human-AI collaboration, the future is here! What's next? #AgenticAI #ArtificialIntelligence #AInews\"\n",
      "\n",
      "Or, if you'd like a more specific post:\n",
      "\n",
      "\"Just in: Researchers at [leading institution] have developed an agentic AI system that can learn from humans and adapt to new situations. This tech has massive potential for industries like healthcare, finance, and more! #AgenticAI #AIresearch #Innovation\"\n",
      "\n",
      "Let me know if you'd like me to adjust anything! \n",
      "\n",
      "**Update**: If you want a more recent and specific news item, I found that researchers at DeepMind just published a paper on \"Learning to Assist Humans through Self-Supervised Reinforcement Learning\" which shows an example of Agentic AI. \n",
      "\n",
      "Here's a Twitter-style post:\n",
      "\n",
      "\"DeepMind's latest: Self-supervised RL enables AI agents to learn from humans & adapt to new tasks! Agentic AI takes a huge leap forward. Can this tech enable more human-AI collaboration? #AgenticAI #DeepMind #AIresearch\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "prompt1=PromptTemplate(\n",
    "    template='Generate a linkedin post about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2=PromptTemplate(\n",
    "    template='Generate a twitter post about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "parser=StrOutputParser()\n",
    "\n",
    "parallel_chain=RunnableParallel({\n",
    "    'linkedin_post':RunnableSequence(prompt1,model1,parser),\n",
    "    'X_post':RunnableSequence(prompt2,model1,parser)\n",
    "})\n",
    "\n",
    "result=parallel_chain.invoke({'topic':'Agentic AI latest news'})\n",
    "\n",
    "print(result['linkedin_post'])\n",
    "print(result['X_post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
